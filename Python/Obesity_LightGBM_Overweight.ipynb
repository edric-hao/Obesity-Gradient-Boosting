{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NZJDpR8ZJuSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kwg1Am_NJfG8"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "with open ('/content/data-overweight.csv') as file:\n",
        "  csv_reader = csv.reader(file)\n",
        "  for row in csv_reader:\n",
        "    if row[0]=='ID':\n",
        "      continue\n",
        "    datum = []\n",
        "    datum.append(float(row[3]))\n",
        "    datum.append(float(row[4]))\n",
        "    if row[1]=='Female':\n",
        "      datum.append(0)\n",
        "    else:\n",
        "      datum.append(1)\n",
        "    datum.append(float(row[2]))\n",
        "    bmi = float(row[4])/(float(row[3])**2)\n",
        "    datum.append(bmi)\n",
        "    if row[5]=='yes':\n",
        "      datum.append(0)\n",
        "    else:\n",
        "      datum.append(1)\n",
        "    if row[6]=='yes':\n",
        "      datum.append(0)\n",
        "    else:\n",
        "      datum.append(1)\n",
        "    datum.append(float(row[7]))\n",
        "    datum.append(float(row[8]))\n",
        "    if row[9]=='no':\n",
        "      datum.append(0)\n",
        "    elif row[9]=='Sometimes':\n",
        "      datum.append(1)\n",
        "    elif row[9]=='Frequently':\n",
        "      datum.append(2)\n",
        "    else:\n",
        "      datum.append(3)\n",
        "    #if row[10]=='yes':\n",
        "      #datum.append(0)\n",
        "    #else:\n",
        "      #datum.append(1)\n",
        "    datum.append(float(row[11]))\n",
        "    if row[12]=='yes':\n",
        "      datum.append(0)\n",
        "    else:\n",
        "      datum.append(1)\n",
        "    datum.append(float(row[13]))\n",
        "    datum.append(float(row[14]))\n",
        "    if row[15]=='no':\n",
        "      datum.append(0)\n",
        "    elif row[15]=='Sometimes':\n",
        "      datum.append(1)\n",
        "    elif row[15]=='Frequently':\n",
        "      datum.append(2)\n",
        "    else:\n",
        "      datum.append(3)\n",
        "    if row[16]=='Walking':\n",
        "      datum.append(0)\n",
        "    elif row[16]=='Bike':\n",
        "      datum.append(1)\n",
        "    elif row[16]=='Motorbike':\n",
        "      datum.append(2)\n",
        "    elif row[16]=='Automobile':\n",
        "      datum.append(3)\n",
        "    else:\n",
        "      datum.append(4)\n",
        "    if row[17]=='Insufficient_Weight':\n",
        "      y.append(0)\n",
        "    elif row[17]=='Normal_Weight':\n",
        "      y.append(1)\n",
        "    elif row[17]=='Overweight':\n",
        "      y.append(2)\n",
        "    elif row[17]=='Obesity_Type_I':\n",
        "      y.append(3)\n",
        "    elif row[17]=='Obesity_Type_II':\n",
        "      y.append(4)\n",
        "    else:\n",
        "      y.append(5)\n",
        "    x.append(datum)\n",
        "print(x)\n",
        "print(y)\n",
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "lQfjIyfP_4yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "import pickle"
      ],
      "metadata": {
        "id": "vSX316C0nAHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "-Rbx4D8tvQWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "uNCgrqDwnFm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = lgb.LGBMClassifier()\n",
        "base_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "qIav2QaqnJPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = base_model.predict(X_test)"
      ],
      "metadata": {
        "id": "gOBROuFUnN_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "vZJEMt08nRZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Objective function to be minimized.\n",
        "    \"\"\"\n",
        "    param = {\n",
        "        \"objective\": \"multiclass\",\n",
        "        \"metric\": \"multi_logloss\",\n",
        "        \"verbosity\": -1,\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "        \"num_class\": 6,\n",
        "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
        "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
        "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
        "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
        "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
        "    }\n",
        "    gbm = lgb.LGBMClassifier(**param)\n",
        "    gbm.fit(X_train, y_train)\n",
        "    preds = gbm.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "YOglTQnnnfSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = TPESampler(seed=1)\n",
        "study = optuna.create_study(study_name=\"lightgbm\", direction=\"maximize\", sampler=sampler)\n",
        "study.optimize(objective, n_trials=500)"
      ],
      "metadata": {
        "id": "JuxvqAhznh0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best parameters:', study.best_params)"
      ],
      "metadata": {
        "id": "oVIYojwEnzqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best value:', study.best_value)"
      ],
      "metadata": {
        "id": "GR2Oy8fbn28U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best trial:', study.best_trial)"
      ],
      "metadata": {
        "id": "ukwJ_0rqn6Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = lgb.LGBMClassifier(**study.best_params)\n",
        "model.fit(X_train, y_train,  feature_name=['Height', 'Weight', 'Gender', 'Age', 'BMI', 'family_history', 'FCHCF', 'FCV',\n",
        "                                           'NMM','CFBM', 'CW', 'CCM', 'PAF', 'TUT', 'CA', 'Transportation'])"
      ],
      "metadata": {
        "id": "NjfIKzFIn9Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "MJB3jTIpn_F9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "E8KI07zPoBK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "iHCZ_vAioD-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "l5S6Kpu0UDyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "shap_values = shap.TreeExplainer(model).shap_values(X_test)\n",
        "shap.summary_plot(shap_values, X_test, feature_names = ['Height', 'Weight', 'Gender', 'Age', 'BMI', 'family_history', 'FCHCF', 'FCV',\n",
        "                                                        'NMM', 'CFBM', 'Smoke', 'CW', 'CCM', 'PAF', 'TUT', 'CA', 'Transportation']\n",
        "                                     , class_names = ['Insufficient_Weight', 'Normal_Weight', 'Overweight',\n",
        "                                                         'Obesity_Level_I', 'Obesity_Level_II', 'Obesity_Level_III'], show = False\n",
        "                                     , class_inds = model.classes_)\n",
        "plt.gcf().set_size_inches(20,10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "asLXhsaUPkO3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}