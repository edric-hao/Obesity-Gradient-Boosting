{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NZJDpR8ZJuSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kwg1Am_NJfG8"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "with open ('/content/data-overweight.csv') as file:\n",
        "  csv_reader = csv.reader(file)\n",
        "  for row in csv_reader:\n",
        "    if row[0]=='ID':\n",
        "      continue\n",
        "    datum = []\n",
        "    datum.append(row[3])\n",
        "    datum.append(row[4])\n",
        "    if row[1]=='Female':\n",
        "      datum.append(0)\n",
        "    else:\n",
        "      datum.append(1)\n",
        "    datum.append(float(row[2]))\n",
        "    bmi = float(row[4])/(float(row[3])**2)\n",
        "    datum.append(bmi)\n",
        "    if row[5]=='yes':\n",
        "      datum.append(0)\n",
        "    else:\n",
        "      datum.append(1)\n",
        "    if row[6]=='yes':\n",
        "      datum.append(0)\n",
        "    else:\n",
        "      datum.append(1)\n",
        "    datum.append(float(row[7]))\n",
        "    datum.append(float(row[8]))\n",
        "    if row[9]=='no':\n",
        "      datum.append(0)\n",
        "    elif row[9]=='Sometimes':\n",
        "      datum.append(1)\n",
        "    elif row[9]=='Frequently':\n",
        "      datum.append(2)\n",
        "    else:\n",
        "      datum.append(3)\n",
        "    #if row[10]=='yes':\n",
        "      #datum.append(0)\n",
        "    #else:\n",
        "      #datum.append(1)\n",
        "    datum.append(float(row[11]))\n",
        "    if row[12]=='yes':\n",
        "      datum.append(0)\n",
        "    else:\n",
        "      datum.append(1)\n",
        "    datum.append(float(row[13]))\n",
        "    datum.append(float(row[14]))\n",
        "    if row[15]=='no':\n",
        "      datum.append(0)\n",
        "    elif row[15]=='Sometimes':\n",
        "      datum.append(1)\n",
        "    elif row[15]=='Frequently':\n",
        "      datum.append(2)\n",
        "    else:\n",
        "      datum.append(3)\n",
        "    if row[16]=='Walking':\n",
        "      datum.append(0)\n",
        "    elif row[16]=='Bike':\n",
        "      datum.append(1)\n",
        "    elif row[16]=='Motorbike':\n",
        "      datum.append(2)\n",
        "    elif row[16]=='Automobile':\n",
        "      datum.append(3)\n",
        "    else:\n",
        "      datum.append(4)\n",
        "    if row[17]=='Insufficient_Weight':\n",
        "      y.append(0)\n",
        "    elif row[17]=='Normal_Weight':\n",
        "      y.append(1)\n",
        "    elif row[17]=='Overweight':\n",
        "      y.append(2)\n",
        "    elif row[17]=='Obesity_Type_I':\n",
        "      y.append(3)\n",
        "    elif row[17]=='Obesity_Type_II':\n",
        "      y.append(4)\n",
        "    else:\n",
        "      y.append(5)\n",
        "    x.append(datum)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "lQfjIyfP_4yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna  # pip install optuna\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import lightgbm as lgb\n",
        "from optuna.integration import LightGBMPruningCallback"
      ],
      "metadata": {
        "id": "vSX316C0nAHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "-Rbx4D8tvQWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial, X, y):\n",
        "    \"\"\"\n",
        "    Objective function to be minimized.\n",
        "    \"\"\"\n",
        "    param = {\n",
        "        \"objective\": \"multiclass\",\n",
        "        \"metric\": \"multi_logloss\",\n",
        "        \"verbosity\": -1,\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "        \"num_class\": 6,\n",
        "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
        "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
        "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
        "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
        "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
        "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
        "    }\n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
        "\n",
        "    cv_scores = np.empty(10)\n",
        "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        model = lgb.LGBMClassifier(**param)\n",
        "        model.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            eval_set=[(X_test, y_test)],\n",
        "            eval_metric=\"multi_logloss\",\n",
        "            early_stopping_rounds=100,\n",
        "            callbacks=[\n",
        "                LightGBMPruningCallback(trial, \"multi_logloss\")\n",
        "            ],  # Add a pruning callback\n",
        "        )\n",
        "        preds = model.predict_proba(X_test)\n",
        "        cv_scores[idx] = log_loss(y_test, preds)\n",
        "\n",
        "    return np.mean(cv_scores)"
      ],
      "metadata": {
        "id": "62yXN8PFINlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "vuXRNdaPNDqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "np.random.seed(0) # Reproducibility \n",
        "num_classes = 6\n",
        "\n",
        "######## Use a dict to track the SHAP values of each observation per CV repitition \n",
        "\n",
        "shap_values_per_cv = dict()\n",
        "for num_class in range(num_classes):\n",
        "    ## Create keys for each Class\n",
        "    shap_values_per_cv[num_class] = {} \n",
        "    ## Then, keys for each sample within each Class\n",
        "    for sample in range(len(x)):\n",
        "        shap_values_per_cv[num_class][sample] = {}"
      ],
      "metadata": {
        "id": "qGuUUHPzO8xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean \n",
        "from sklearn.metrics import accuracy_score\n",
        "cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "cv_scores = np.empty(5)\n",
        "for idx, (train_outer_idx, test_outer_idx) in enumerate(cv_outer.split(x, y)):\n",
        "    X_train, X_test = x[train_outer_idx], x[test_outer_idx]\n",
        "    y_train, y_test = y[train_outer_idx], y[test_outer_idx]\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n",
        "    func = lambda trial: objective(trial, X_train, y_train)\n",
        "    study.optimize(func, n_trials=500)\n",
        "\n",
        "    print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
        "    print(f\"\\tBest params:\")\n",
        "    for key, value in study.best_params.items():\n",
        "        print(f\"\\t\\t{key}: {value}\")\n",
        "    model = lgb.LGBMClassifier(**study.best_params)\n",
        "    result = model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    cv_scores[idx] = accuracy\n",
        "\n",
        "    explainer = shap.TreeExplainer(result) \n",
        "    shap_values = explainer.shap_values(X_test)\n",
        "    # Extract SHAP information per fold per sample\n",
        "    for j in range(num_classes):\n",
        "        for k, test_index in enumerate(test_outer_idx):\n",
        "            shap_values_per_cv[j][test_index] = shap_values[j][k]"
      ],
      "metadata": {
        "id": "o1OHBAkk3UVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish lists to keep average Shap values, their Stds, and their min and max\n",
        "average_shap_values, stds, ranges = [],[],[]\n",
        "\n",
        "for i in range(num_classes):\n",
        "    a, b, c = [],[],[]\n",
        "    for j in range(len(shap_values_per_cv[0])):   \n",
        "        df_per_obs = pd.DataFrame.from_dict(shap_values_per_cv[i][j]) # Get all SHAP values for sample number i\n",
        "        # Get relevant statistics for every sample\n",
        "        a.append(df_per_obs.mean(axis=1).values)\n",
        "        b.append(df_per_obs.std(axis=1).values)\n",
        "        c.append(df_per_obs.max(axis=1).values-df_per_obs.min(axis=1).values)\n",
        "    average_shap_values.append(np.array(a)) \n",
        "    stds.append(b)\n",
        "    ranges.append(c)"
      ],
      "metadata": {
        "id": "BF3bOOlgO1xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "\n",
        "shap.summary_plot(average_shap_values, x, feature_names = ['Height', 'Weight', 'Gender', 'Age', 'BMI', 'family_history', 'FCHCF', 'FCV',\n",
        "                                                           'NMM', 'CFBM', 'Smoke', 'CCM', 'PAF', 'TUT', 'CA', 'Transportation']\n",
        "                                        , class_names = ['Insufficient_Weight', 'Normal_Weight', 'Overweight',\n",
        "                                                         'Obesity_Level_I', 'Obesity_Level_II', 'Obesity_Level_III'], show = False\n",
        "                                        , class_inds = model.classes_)\n",
        "plt.gcf().set_size_inches(20,10)\n",
        "plt.show()\n",
        "\n",
        "print(\"Nested Stratified Cross Validation Scores: \" + str(cv_scores))\n",
        "print(\"Average CV Score: \" + str(mean(cv_scores)))\n",
        "print(\"Number of CV Scores used in Average: \" + str(len(cv_scores)))"
      ],
      "metadata": {
        "id": "zep1qRsXPAnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n",
        "func = lambda trial: objective(trial, x, y)\n",
        "study.optimize(func, n_trials=500)"
      ],
      "metadata": {
        "id": "dUGjbzKw19hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
        "print(f\"\\tBest params:\")\n",
        "\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"\\t\\t{key}: {value}\")"
      ],
      "metadata": {
        "id": "wsukuRv02jlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "model = lgb.LGBMClassifier(**study.best_params)\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "scores = cross_val_score(model, x, y, cv=skf)"
      ],
      "metadata": {
        "id": "bO6Svu_Y3rff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "id": "RhBnDT__4FAm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}